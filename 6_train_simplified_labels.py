#!/usr/bin/env python3
"""
ç®€åŒ–æ ‡ç­¾è®­ç»ƒè„šæœ¬
å°†5ç±»æ ‡ç­¾ç®€åŒ–ä¸º4ç±»ï¼šåˆå¹¶ èƒŒæ™¯(0) å’Œ è¿‡æ¸¡(4) ä¸º "èƒŒæ™¯/è¿‡æ¸¡(0)"

æ–°æ ‡ç­¾æ˜ å°„ï¼š
- 0: èƒŒæ™¯/è¿‡æ¸¡ (åŸ0å’Œ4)
- 1: å‡†å¤‡ (åŸ1)
- 2: æ ¸å¿ƒ (åŸ2)
- 3: æ¢å¤ (åŸ3)
"""

import argparse
import os
import json
import glob
import numpy as np
import pandas as pd
import matplotlib
matplotlib.use('Agg')  # ä½¿ç”¨éäº¤äº’å¼åç«¯ï¼Œé¿å…çº¿ç¨‹é”™è¯¯
import matplotlib.pyplot as plt
import seaborn as sns
import pickle

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import StratifiedGroupKFold, LeaveOneGroupOut, GroupShuffleSplit
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.inspection import permutation_importance

plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False


def find_latest_features_file(search_dir='datasets'):
    pattern = os.path.join(search_dir, '*features*.csv')
    files = glob.glob(pattern, recursive=True)
    if not files:
        return None
    return max(files, key=os.path.getmtime)


def simplify_labels(y):
    """å°†5ç±»æ ‡ç­¾ç®€åŒ–ä¸º4ç±»"""
    # åŸæ ‡ç­¾: 0=èƒŒæ™¯, 1=å‡†å¤‡, 2=æ ¸å¿ƒ, 3=æ¢å¤, 4=è¿‡æ¸¡
    # æ–°æ ‡ç­¾: 0=èƒŒæ™¯/è¿‡æ¸¡, 1=å‡†å¤‡, 2=æ ¸å¿ƒ, 3=æ¢å¤
    y_new = y.copy()
    y_new[y == 4] = 0  # è¿‡æ¸¡ â†’ èƒŒæ™¯/è¿‡æ¸¡
    return y_new


def create_stroke_groups(df):
    """
    åˆ›å»ºåˆ†ç»„æ ‡è¯†ï¼Œä¼˜å…ˆçº§ï¼šsession_id > stroke_id > time-based
    
    ç”¨äº Leave-One-Session-Out (LOSO) äº¤å‰éªŒè¯
    """
    # ä¼˜å…ˆçº§1: ä½¿ç”¨ session_id (æœ€ä½³å®è·µï¼Œç”¨äºLOSO)
    if 'session_id' in df.columns:
        groups = df['session_id'].values
        n_groups = len(np.unique(groups))
        print(f"[INFO] âœ“ ä½¿ç”¨ session_id åˆ†ç»„ï¼Œå…± {n_groups} ä¸ªç‹¬ç«‹è®­ç»ƒä¼šè¯")
        print(f"[INFO]   â†’ å°†æ‰§è¡Œ Leave-One-Session-Out (LOSO) éªŒè¯")
        return groups, 'session_id'
    
    # ä¼˜å…ˆçº§2: å›é€€åˆ° stroke_id
    if 'stroke_id' in df.columns:
        groups = df['stroke_id'].values
        n_groups = len(np.unique(groups))
        print(f"[WARNING] session_id æœªæ‰¾åˆ°ï¼Œä½¿ç”¨ stroke_id åˆ†ç»„ï¼Œå…± {n_groups} ç»„")
        print(f"[WARNING]   â†’ å°†æ‰§è¡Œ GroupShuffleSplitï¼ˆè­¦å‘Šï¼šå¯èƒ½å­˜åœ¨ä¼ªæ³›åŒ–ï¼‰")
        return groups, 'stroke_id'
    
    # ä¼˜å…ˆçº§3: å›é€€åˆ°æ—¶é—´åˆ†ç»„ï¼ˆæœ€å·®æ–¹æ¡ˆï¼‰
    if 'time' in df.columns:
        groups = (df['time'].values).astype(int)
    else:
        groups = np.arange(len(df)) // 100
    
    n_groups = len(np.unique(groups))
    print(f"[WARNING] æœªæ‰¾åˆ° session_id æˆ– stroke_idï¼Œä½¿ç”¨ä¼ªåˆ†ç»„ {n_groups} ä¸ª")
    print(f"[WARNING]   â†’ äº¤å‰éªŒè¯ç»“æœå¯èƒ½ä¸å¯é ï¼")
    return groups, 'pseudo'


def plot_confusion_matrix(y_true, y_pred, out_path, labels):
    cm = confusion_matrix(y_true, y_pred)
    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
    
    fig, ax = plt.subplots(figsize=(8, 6))
    sns.heatmap(cm_norm, annot=False, cmap='YlOrRd',
                xticklabels=labels, yticklabels=labels, ax=ax)
    
    for i in range(len(labels)):
        for j in range(len(labels)):
            pct = cm_norm[i, j] * 100
            count = cm[i, j]
            color = 'white' if cm_norm[i, j] > 0.5 else 'black'
            ax.text(j + 0.5, i + 0.5, f'{pct:.1f}%\n({count})',
                   ha='center', va='center', fontsize=11, color=color)
    
    ax.set_title('æ··æ·†çŸ©é˜µ - ç®€åŒ–4ç±»æ ‡ç­¾', fontsize=14)
    ax.set_ylabel('çœŸå®æ ‡ç­¾')
    ax.set_xlabel('é¢„æµ‹æ ‡ç­¾')
    plt.tight_layout()
    plt.savefig(out_path, dpi=150)
    plt.close()
    print(f"[INFO] æ··æ·†çŸ©é˜µå·²ä¿å­˜: {out_path}")


def plot_feature_importance(model, feature_cols, out_path, top_n=20):
    """ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§å›¾"""
    importances = model.feature_importances_
    indices = np.argsort(importances)[::-1][:top_n]
    
    fig, ax = plt.subplots(figsize=(12, 8))
    colors = plt.cm.viridis(np.linspace(0.2, 0.8, len(indices)))
    
    ax.barh(range(len(indices)), importances[indices][::-1], color=colors)
    ax.set_yticks(range(len(indices)))
    ax.set_yticklabels([feature_cols[i][:25] for i in indices[::-1]], fontsize=10)
    ax.set_xlabel('ç‰¹å¾é‡è¦æ€§', fontsize=12)
    ax.set_title(f'Random Forest ç‰¹å¾é‡è¦æ€§ (Top {top_n})', fontsize=14)
    ax.grid(axis='x', alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(out_path, dpi=150)
    plt.close()
    print(f"[INFO] ç‰¹å¾é‡è¦æ€§å›¾å·²ä¿å­˜: {out_path}")


def plot_classification_metrics(report, labels, out_path):
    """ç»˜åˆ¶åˆ†ç±»æŒ‡æ ‡å¯¹æ¯”å›¾ï¼ˆPrecision/Recall/F1ï¼‰"""
    metrics = ['precision', 'recall', 'f1-score']
    
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    colors = ['#2196F3', '#4CAF50', '#FF9800', '#E91E63']
    
    for ax_idx, metric in enumerate(metrics):
        values = [report.get(label, {}).get(metric, 0) for label in labels]
        bars = axes[ax_idx].bar(labels, values, color=colors[:len(labels)], alpha=0.8)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, val in zip(bars, values):
            axes[ax_idx].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,
                            f'{val:.2f}', ha='center', va='bottom', fontsize=10)
        
        axes[ax_idx].set_ylim(0, 1.15)
        axes[ax_idx].set_ylabel(metric.capitalize(), fontsize=12)
        axes[ax_idx].set_title(f'{metric.capitalize()} per Class', fontsize=13)
        axes[ax_idx].grid(axis='y', alpha=0.3)
        axes[ax_idx].tick_params(axis='x', rotation=15)
    
    plt.suptitle('åˆ†ç±»æŒ‡æ ‡å¯¹æ¯”', fontsize=15, fontweight='bold')
    plt.tight_layout()
    plt.savefig(out_path, dpi=150)
    plt.close()
    print(f"[INFO] åˆ†ç±»æŒ‡æ ‡å¯¹æ¯”å›¾å·²ä¿å­˜: {out_path}")


def plot_cv_fold_results(fold_f1s, out_path):
    """ç»˜åˆ¶äº¤å‰éªŒè¯å„æŠ˜ç»“æœ"""
    fig, ax = plt.subplots(figsize=(10, 5))
    
    folds = range(1, len(fold_f1s) + 1)
    colors = ['#4CAF50' if f1 > np.mean(fold_f1s) else '#FF5722' for f1 in fold_f1s]
    bars = ax.bar(folds, fold_f1s, color=colors, alpha=0.8, edgecolor='black')
    
    # æ·»åŠ å‡å€¼çº¿
    mean_f1 = np.mean(fold_f1s)
    ax.axhline(mean_f1, color='#2196F3', linestyle='--', linewidth=2, 
               label=f'å¹³å‡ F1: {mean_f1:.4f}')
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, val in zip(bars, fold_f1s):
        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
               f'{val:.3f}', ha='center', va='bottom', fontsize=11)
    
    ax.set_xlabel('Fold', fontsize=12)
    ax.set_ylabel('Macro F1', fontsize=12)
    ax.set_title('äº¤å‰éªŒè¯å„æŠ˜ Macro F1 åˆ†æ•°', fontsize=14)
    ax.set_xticks(folds)
    ax.set_ylim(0, 1.1)
    ax.legend(loc='lower right', fontsize=11)
    ax.grid(axis='y', alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(out_path, dpi=150)
    plt.close()
    print(f"[INFO] äº¤å‰éªŒè¯ç»“æœå›¾å·²ä¿å­˜: {out_path}")


def main():
    parser = argparse.ArgumentParser(description='ç®€åŒ–æ ‡ç­¾è®­ç»ƒ')
    parser.add_argument('--data', type=str, default=None)
    parser.add_argument('--cv_splits', type=int, default=5)
    parser.add_argument('--n_estimators', type=int, default=300)
    parser.add_argument('--out_dir', type=str, default='models')
    parser.add_argument('--vis_dir', type=str, default='datasets/visualizations')
    args = parser.parse_args()
    
    # åŠ è½½æ•°æ®
    data_file = args.data or find_latest_features_file()
    if not data_file:
        print("[ERROR] æœªæ‰¾åˆ°ç‰¹å¾æ–‡ä»¶!")
        return
    
    print(f"\n[INFO] åŠ è½½: {data_file}")
    df = pd.read_csv(data_file)
    print(f"[INFO] æ ·æœ¬æ•°: {len(df)}")
    
    # åˆ†ç¦»ç‰¹å¾å’Œæ ‡ç­¾
    metadata_cols = ['label', 'time', 'stroke_id', 'session_id', 'date', 
                     'rower_level', 'boat_type', 'device_id']
    feature_cols = [c for c in df.columns if c not in metadata_cols]
    X = df[feature_cols].values
    y_original = df['label'].values
    
    # ç®€åŒ–æ ‡ç­¾
    y = simplify_labels(y_original)
    labels = ['èƒŒæ™¯/è¿‡æ¸¡', 'å‡†å¤‡', 'æ ¸å¿ƒ', 'æ¢å¤']
    
    print("\n[INFO] æ ‡ç­¾ç®€åŒ–æ˜ å°„:")
    print("  åŸ5ç±» â†’ æ–°4ç±»")
    print("  èƒŒæ™¯(0) + è¿‡æ¸¡(4) â†’ èƒŒæ™¯/è¿‡æ¸¡(0)")
    print("  å‡†å¤‡(1) â†’ å‡†å¤‡(1)")
    print("  æ ¸å¿ƒ(2) â†’ æ ¸å¿ƒ(2)")
    print("  æ¢å¤(3) â†’ æ¢å¤(3)")
    
    # åˆ›å»ºåˆ†ç»„
    groups, group_type = create_stroke_groups(df)
    n_unique_groups = len(np.unique(groups))
    
    # æ ‡ç­¾åˆ†å¸ƒ
    print("\n[INFO] æ–°æ ‡ç­¾åˆ†å¸ƒ:")
    for i, label in enumerate(labels):
        count = np.sum(y == i)
        pct = count / len(y) * 100
        print(f"  {label} ({i}): {count:6d} ({pct:5.2f}%)")
    
    # ========== é€‰æ‹©äº¤å‰éªŒè¯ç­–ç•¥ ==========
    # æ ¹æ®åˆ†ç»„ç±»å‹é€‰æ‹©æœ€ä½³CVç­–ç•¥
    if group_type == 'session_id' and n_unique_groups >= 3:
        # ä½¿ç”¨ Leave-One-Session-Out (æœ€ä¸¥æ ¼çš„æ³›åŒ–æµ‹è¯•)
        cv_strategy = LeaveOneGroupOut()
        cv_name = "Leave-One-Session-Out (LOSO)"
        n_splits = n_unique_groups
        print(f"\n[INFO] ğŸ¯ æ‰§è¡Œ {cv_name} éªŒè¯...")
        print(f"[INFO]   æ¯æ¬¡ç•™å‡º1ä¸ªå®Œæ•´è®­ç»ƒä¼šè¯ä½œä¸ºæµ‹è¯•é›†")
        print(f"[INFO]   æ€»å…± {n_splits} æ¬¡äº¤å‰éªŒè¯")
    else:
        # å›é€€åˆ° GroupShuffleSplit
        cv_strategy = GroupShuffleSplit(n_splits=args.cv_splits, test_size=0.2, random_state=42)
        cv_name = f"GroupShuffleSplit ({args.cv_splits}æ¬¡)"
        n_splits = args.cv_splits
        print(f"\n[INFO] æ‰§è¡Œ {cv_name} éªŒè¯...")
        if group_type != 'session_id':
            print(f"[WARNING] âš ï¸  æœªä½¿ç”¨session_idï¼ŒéªŒè¯ç»“æœå¯èƒ½å­˜åœ¨ä¼ªæ³›åŒ–ï¼")
    
    y_pred_cv = np.full(len(y), -1, dtype=int)  # -1è¡¨ç¤ºæœªé¢„æµ‹
    fold_f1s = []
    fold_results = []  # å­˜å‚¨æ¯ä¸ªfoldçš„è¯¦ç»†ç»“æœ
    
    for fold, (train_idx, test_idx) in enumerate(cv_strategy.split(X, y, groups), 1):
        # è·å–å½“å‰foldæµ‹è¯•çš„sessionä¿¡æ¯
        if group_type == 'session_id':
            test_sessions = np.unique(groups[test_idx])
            session_info = f", Test Session: {test_sessions[0]}"
        else:
            session_info = ""
        
        print(f"  Fold {fold}/{n_splits}: Train={len(train_idx)}, Test={len(test_idx)}{session_info}")
        
        rf = RandomForestClassifier(
            n_estimators=args.n_estimators,
            max_depth=None,
            min_samples_leaf=5,
            class_weight=None,
            n_jobs=-1,
            random_state=42 + fold
        )
        rf.fit(X[train_idx], y[train_idx])
        pred = rf.predict(X[test_idx])
        y_pred_cv[test_idx] = pred
        
        # è®¡ç®—æ¯æŠ˜çš„F1
        from sklearn.metrics import f1_score
        fold_f1 = f1_score(y[test_idx], pred, average='macro', zero_division=0)
        fold_f1s.append(fold_f1)
        
        # å­˜å‚¨è¯¦ç»†ç»“æœ
        fold_result = {
            'fold': fold,
            'f1_score': fold_f1,
            'n_train': len(train_idx),
            'n_test': len(test_idx)
        }
        if group_type == 'session_id':
            fold_result['test_session'] = str(test_sessions[0])
        fold_results.append(fold_result)
        
        print(f"    Fold {fold} Macro F1: {fold_f1:.4f}")
    
    # å¯¹æœªè¢«é¢„æµ‹çš„æ ·æœ¬ç”¨æœ€åä¸€ä¸ªæ¨¡å‹é¢„æµ‹
    not_predicted = y_pred_cv == -1
    if np.any(not_predicted):
        y_pred_cv[not_predicted] = rf.predict(X[not_predicted])
    
    print(f"\n  {'='*50}")
    print(f"  {cv_name} ç»“æœæ±‡æ€»")
    print(f"  {'='*50}")
    print(f"  å¹³å‡ Macro F1: {np.mean(fold_f1s):.4f} Â± {np.std(fold_f1s):.4f}")
    print(f"  æœ€ä½³ Fold F1:  {np.max(fold_f1s):.4f}")
    print(f"  æœ€å·® Fold F1:  {np.min(fold_f1s):.4f}")
    print(f"  {'='*50}")
    
    # è¯„ä¼°
    print("\n" + "="*60)
    print(f"{cv_name} - ç®€åŒ–æ ‡ç­¾ç»“æœ")
    print("="*60)
    
    report = classification_report(y, y_pred_cv, target_names=labels, 
                                   output_dict=True, zero_division=0)
    print("\nåˆ†ç±»æŠ¥å‘Š:")
    print(classification_report(y, y_pred_cv, target_names=labels, zero_division=0))
    
    macro_f1 = report['macro avg']['f1-score']
    accuracy = report['accuracy']
    print(f"\nâ­ Macro F1: {macro_f1:.4f}")
    print(f"â­ Accuracy: {accuracy:.4f}")
    
    # ä¿å­˜å¯è§†åŒ–
    os.makedirs(args.vis_dir, exist_ok=True)
    os.makedirs(args.out_dir, exist_ok=True)
    
    plot_confusion_matrix(y, y_pred_cv,
                         os.path.join(args.vis_dir, 'rf_simplified_confusion_matrix.png'),
                         labels)
    
    # æ–°å¢ï¼šåˆ†ç±»æŒ‡æ ‡å¯¹æ¯”å›¾
    plot_classification_metrics(report, labels,
                               os.path.join(args.vis_dir, 'rf_classification_metrics.png'))
    
    # æ–°å¢ï¼šäº¤å‰éªŒè¯å„æŠ˜ç»“æœå›¾
    plot_cv_fold_results(fold_f1s,
                        os.path.join(args.vis_dir, 'rf_cv_fold_results.png'))
    
    # è®­ç»ƒæœ€ç»ˆæ¨¡å‹
    print("\n[INFO] è®­ç»ƒæœ€ç»ˆæ¨¡å‹...")
    rf_final = RandomForestClassifier(
        n_estimators=args.n_estimators,
        class_weight=None,
        n_jobs=-1,
        random_state=42
    )
    rf_final.fit(X, y)
    
    # æ–°å¢ï¼šç‰¹å¾é‡è¦æ€§å›¾
    plot_feature_importance(rf_final, feature_cols,
                           os.path.join(args.vis_dir, 'rf_feature_importance.png'),
                           top_n=25)
    
    # ä¿å­˜
    model_path = os.path.join(args.out_dir, 'rf_simplified_model.pkl')
    with open(model_path, 'wb') as f:
        pickle.dump({
            'model': rf_final,
            'feature_cols': feature_cols,
            'labels': labels,
            'label_mapping': '0=èƒŒæ™¯/è¿‡æ¸¡, 1=å‡†å¤‡, 2=æ ¸å¿ƒ, 3=æ¢å¤'
        }, f)
    print(f"[INFO] æ¨¡å‹å·²ä¿å­˜: {model_path}")
    
    # ä¿å­˜æŠ¥å‘Š
    report_data = {
        'n_samples': len(df),
        'n_classes': 4,
        'cv_strategy': cv_name,
        'n_unique_groups': int(n_unique_groups),
        'group_type': group_type,
        'macro_f1': float(macro_f1),
        'macro_f1_std': float(np.std(fold_f1s)),
        'accuracy': float(accuracy),
        'fold_results': fold_results,
        'per_class_f1': {label: float(report.get(label, {}).get('f1-score', 0)) 
                        for label in labels}
    }
    report_path = os.path.join(args.out_dir, 'rf_simplified_report.json')
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report_data, f, indent=2, ensure_ascii=False)
    
    print("\n" + "="*60)
    print("å®Œæˆï¼")
    print("="*60)
    print(f"â­ ç®€åŒ–4ç±» Macro F1: {macro_f1:.4f}")
    print(f"â­ å¯¹æ¯”åŸ5ç±» Macro F1: ~0.54")
    print(f"  æ”¹å–„: {(macro_f1 - 0.54) * 100:+.1f}%")


if __name__ == '__main__':
    main()
